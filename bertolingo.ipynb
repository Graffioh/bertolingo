{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "_tbYiO0VGAzv"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ay0W6VMGFzx"
   },
   "source": [
    "# Purpose\n",
    "I am gonna develop a translation model based on attention (both encoding and decoding)\n",
    "\n",
    "From \"\"\"\"**SCRATCH**!!!!**!!!\"\"\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeOwpeRGMQ6y"
   },
   "source": [
    "English -> Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luo94xsnINHz",
    "outputId": "36e18739-9066-4829-e946-f2e2157704a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'en': \"What's going on?\", 'it': 'Che succede?'}}\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"Helsinki-NLP/opus-100\", \"en-it\")\n",
    "\n",
    "example = ds['train'][100]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr8gt4F0GveI"
   },
   "source": [
    "Process dataset into training and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "1esyM3FVEern"
   },
   "outputs": [],
   "source": [
    "# This function will process a \"batch\" of examples at once\n",
    "def extract_translations(batch):\n",
    "  return {\n",
    "      'en_text': [t['en'] for t in batch['translation']],\n",
    "      'it_text': [t['it'] for t in batch['translation']],\n",
    "  }\n",
    "\n",
    "# .map() will apply this function to the whole dataset very quickly\n",
    "# batched=True is the key to making it fast\n",
    "processed_ds_train = ds['train'].map(extract_translations, batched=True)\n",
    "\n",
    "x_train = processed_ds_train['en_text']\n",
    "y_train = processed_ds_train['it_text']\n",
    "\n",
    "processed_ds_val = ds['validation'].map(extract_translations, batched=True)\n",
    "\n",
    "x_val = processed_ds_val['en_text']\n",
    "y_val = processed_ds_val['it_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KKCirq1MVKB"
   },
   "source": [
    "Character level tokenizer just like karpathy tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "61XGv8VWIQzU"
   },
   "outputs": [],
   "source": [
    "all_text = \"\".join(x_train) + \"\".join(y_train)\n",
    "chars = sorted(list(set(all_text)))\n",
    "\n",
    "stoi = {c:i for i, c in enumerate(chars)}\n",
    "stoi['<PAD>'] = len(stoi)\n",
    "\n",
    "itos = {i: ch for ch, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLgjQXcRaEVq"
   },
   "source": [
    "Translation dataset struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "wAWvnPUoaEVq"
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, en_texts, it_texts, stoi, max_len=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            en_texts: List of English sentences\n",
    "            it_texts: List of Italian sentences\n",
    "            stoi: Character to index mapping\n",
    "            max_len: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Filter pairs that fit within max_len so that we can fit them into the context window\n",
    "        filtered_pairs = [\n",
    "            (en, it) for en, it in zip(en_texts, it_texts)\n",
    "            if len(en) <= max_len and len(it) <= max_len\n",
    "        ]\n",
    "\n",
    "        if filtered_pairs:\n",
    "            self.en_texts, self.it_texts = zip(*filtered_pairs)\n",
    "        else:\n",
    "            self.en_texts, self.it_texts = [], []\n",
    "\n",
    "        self.stoi = stoi\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.en_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Encode the texts\n",
    "        en_encoded = torch.tensor([self.stoi[char] for char in self.en_texts[idx]])\n",
    "        it_encoded = torch.tensor([self.stoi[char] for char in self.it_texts[idx]])\n",
    "\n",
    "        return en_encoded, it_encoded\n",
    "\n",
    "# This is used by the dataloader to stack together the batch into one tensor by using padding\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to pad sequences in each batch\n",
    "    Args:\n",
    "        batch: List of tuples (en_tensor, it_tensor)\n",
    "    Returns:\n",
    "        x_batch: Padded English sequences\n",
    "        y_batch: Padded Italian sequences\n",
    "    \"\"\"\n",
    "    en_batch, it_batch = zip(*batch)\n",
    "\n",
    "    # Pad sequences\n",
    "    x_batch = pad_sequence(en_batch, batch_first=True, padding_value=stoi['<PAD>'])\n",
    "    y_batch = pad_sequence(it_batch, batch_first=True, padding_value=stoi['<PAD>'])\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "hJUWOMB5B25o"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(stoi)\n",
    "context_window = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCx8KuF7Kcnp"
   },
   "source": [
    "Pick n samples for experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "KBz9HdqIKE6x"
   },
   "outputs": [],
   "source": [
    "sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5wOknT-aEVr",
    "outputId": "9fdcebc5-733a-42ac-de8c-e927b6c53d7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples subset: 1000\n",
      "Validation samples: 1681\n",
      "Batch x shape: torch.Size([32, 123])\n",
      "Batch y shape: torch.Size([32, 78])\n",
      "Sample x: tensor([  40,   69,   89,   14, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290])\n",
      "Sample y: tensor([  37,   72,   73,    1, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290, 1290,\n",
      "        1290, 1290, 1290, 1290, 1290, 1290])\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = TranslationDataset(x_train, y_train, stoi, max_len=context_window)\n",
    "val_dataset = TranslationDataset(x_val, y_val, stoi, max_len=context_window)\n",
    "\n",
    "# For experimenting with smaller samples\n",
    "train_dataset_subset = Subset(train_dataset, range(min(sample_size, len(train_dataset))))\n",
    "\n",
    "print(f\"Training samples subset: {len(train_dataset_subset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0  # Set to 0 for debugging, increase for faster loading\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Test the data loader\n",
    "for x_batch, y_batch in train_loader:\n",
    "    print(\"Batch x shape:\", x_batch.shape)\n",
    "    print(\"Batch y shape:\", y_batch.shape)\n",
    "    print(\"Sample x:\", x_batch[0])\n",
    "    print(\"Sample y:\", y_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw0Ix8mR_XlO"
   },
   "source": [
    "Embedding (Token and Positional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "4am1ab_s_W9Q"
   },
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "  \"\"\"\n",
    "  Embedding layer for the tokens\n",
    "\n",
    "  Args:\n",
    "    vocab_size: size of the vocabulary\n",
    "    d_embd: dimension of the embeddings\n",
    "    padding_idx: index of the padding token\n",
    "  \"\"\"\n",
    "  def __init__(self, vocab_size, d_embd, padding_idx=None):\n",
    "    super().__init__()\n",
    "    # for translation task we should have padding_idx = stoi['<PAD>'] to identify the padding tokens\n",
    "    self.embd = nn.Embedding(vocab_size, d_embd, padding_idx=padding_idx)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.embd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "4AZRW9jnADzd"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "  \"\"\"\n",
    "  Embedding layer for the positional encodings\n",
    "\n",
    "  Args:\n",
    "    n_tokens: number of tokens in the sequence\n",
    "    d_embd: dimension of the embeddings\n",
    "  \"\"\"\n",
    "  def __init__(self, n_tokens, d_embd):\n",
    "    super().__init__()\n",
    "    self.embd = nn.Embedding(n_tokens, d_embd)\n",
    "\n",
    "  def forward(self, x):\n",
    "    T = x.shape[1]\n",
    "    pos = torch.arange(T, device=x.device)\n",
    "    return self.embd(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgX4pkWaBXbB"
   },
   "source": [
    "Single Head (with causal and padding masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "1w6NQbthNP65"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "  \"\"\"\n",
    "  Single Head of the attention mechanism\n",
    "\n",
    "  Args:\n",
    "    d_embd: dimension of the embeddings\n",
    "    head_size: dimension of the head\n",
    "    dropout: dropout rate\n",
    "  \"\"\"\n",
    "  def __init__(self, d_embd, head_size, dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.query = nn.Linear(d_embd, head_size, bias=False)\n",
    "    self.key = nn.Linear(d_embd, head_size, bias=False)\n",
    "    self.value = nn.Linear(d_embd, head_size, bias=False)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.register_buffer('tril', torch.tril(torch.ones(context_window, context_window)))\n",
    "\n",
    "  def forward(self, x, src_kv=None, key_padding_mask=None, causal_mask=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, T, d_embd) - Input tensor\n",
    "        src_kv: (B, T, d_embd) - Source key and value tensor\n",
    "        key_padding_mask: (B, T) - Boolean mask (True for padding positions)\n",
    "        causal_mask: bool - Whether to apply causal mask\n",
    "    \"\"\"\n",
    "    _, q_pos, _ = x.shape\n",
    "\n",
    "    # (B, T, d_embd) -> (B, pos, head_size)\n",
    "    q = self.query(x)\n",
    "    if src_kv is not None:\n",
    "      k = self.key(src_kv)\n",
    "      v = self.value(src_kv)\n",
    "    else:\n",
    "      k = self.key(x)\n",
    "      v = self.value(x)\n",
    "\n",
    "    # (B, q_pos, head_size) @ (B, (k_pos, head_size)^T) -> (B, q_pos, k_pos)\n",
    "    qk = (q @ k.transpose(-2, -1)) * (1 / math.sqrt(k.size(-1)))\n",
    "\n",
    "    # for decoder\n",
    "    if causal_mask:\n",
    "      # Note: k_pos = q_pos\n",
    "      qk = qk.masked_fill(self.tril[:q_pos, :q_pos] == 0, float('-inf')) # (B, q_pos, q_pos)\n",
    "\n",
    "    if key_padding_mask is not None:\n",
    "      expanded_mask = key_padding_mask.unsqueeze(1) # (B, 1, k_pos)\n",
    "      qk = qk.masked_fill(expanded_mask, float('-inf')) # (B, q_pos, k_pos)\n",
    "\n",
    "    attn = torch.softmax(qk, dim=-1)\n",
    "    attn = self.dropout(attn)\n",
    "    out = attn @ v\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "48PHiZ3EaEVs"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  \"\"\"\n",
    "  Multiple heads of attention in parallel\n",
    "\n",
    "  Args:\n",
    "    d_embd: dimension of the embeddings\n",
    "    n_heads: number of attention heads\n",
    "    dropout: dropout rate\n",
    "  \"\"\"\n",
    "  def __init__(self, d_embd, n_heads, dropout=0.1):\n",
    "    super().__init__()\n",
    "    assert d_embd % n_heads == 0, \"d_embd must be divisible by n_heads\"\n",
    "\n",
    "    self.n_heads = n_heads\n",
    "    self.head_size = d_embd // n_heads\n",
    "\n",
    "    # Create multiple heads in parallel\n",
    "    self.heads = nn.ModuleList([Head(d_embd, self.head_size, dropout) for _ in range(n_heads)])\n",
    "\n",
    "    self.proj = nn.Linear(d_embd, d_embd)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x, src=None, key_padding_mask=None, causal_mask=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, T_q, d_embd) - Query input tensor\n",
    "        src: (B, T_kv, d_embd) - Key/Value input tensor (for cross-attention)\n",
    "        key_padding_mask: (B, T_kv) - Boolean mask (True for padding positions)\n",
    "        causal_mask: bool - Whether to apply causal mask\n",
    "    Returns:\n",
    "        (B, T_q, d_embd) - Attention output\n",
    "    \"\"\"\n",
    "    # Run all heads in parallel and concatenate outputs\n",
    "    # Each head outputs (B, T_q, head_size)\n",
    "    out = torch.cat([h(x, src, key_padding_mask, causal_mask) for h in self.heads], dim=-1)\n",
    "\n",
    "    # Output projection and dropout\n",
    "    out = self.dropout(self.proj(out))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3SzhjZxaEVt"
   },
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "Z74Zo41IaEVt"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron\n",
    "\n",
    "    Args:\n",
    "        d_embd: dimension of the embeddings\n",
    "        dropout: dropout rate\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embd, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_embd)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_embd, 4 * d_embd),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * d_embd, d_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(self.ln1(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icX_NYmSaEVt"
   },
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "ykjdCTbBaEVt"
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder block with:\n",
    "    1. Multi-Head Self-attention\n",
    "    2. Feed-forward network\n",
    "\n",
    "    Args:\n",
    "        d_embd: dimension of the embeddings\n",
    "        n_heads: number of attention heads\n",
    "        dropout: dropout rate\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embd, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_embd)\n",
    "        self.attn = MultiHeadAttention(d_embd, n_heads, dropout)\n",
    "        self.ln2 = nn.LayerNorm(d_embd)\n",
    "        self.mlp = MLP(d_embd, dropout)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, T, d_embd) - Input tensor\n",
    "            key_padding_mask: (B, T) - Boolean mask (True for padding positions)\n",
    "        Returns:\n",
    "            (B, T, d_embd) - Output tensor\n",
    "        \"\"\"\n",
    "        x = x + self.attn(self.ln1(x), src=None, key_padding_mask=key_padding_mask, causal_mask=False)\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "ePTcHPE1aEVt"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  \"\"\"\n",
    "  Encoder with multiple blocks of multi-head self-attention and feed-forward networks\n",
    "\n",
    "  Args:\n",
    "    vocab_size: size of the vocabulary\n",
    "    d_embd: dimension of the embeddings\n",
    "    n_heads: number of attention heads\n",
    "    dropout: dropout rate\n",
    "    n_blocks: number of blocks in the encoder\n",
    "  \"\"\"\n",
    "  def __init__(self, vocab_size, d_embd, n_heads, dropout=0.1, n_blocks=4):\n",
    "    super().__init__()\n",
    "    self.tok_emb = TokenEmbedding(vocab_size, d_embd, padding_idx=stoi['<PAD>'])\n",
    "    self.pos_emb = PositionalEmbedding(context_window, d_embd)\n",
    "    self.blocks = nn.ModuleList([EncoderBlock(d_embd, n_heads, dropout) for _ in range(n_blocks)])\n",
    "    self.ln_f = nn.LayerNorm(d_embd)\n",
    "\n",
    "  def forward(self, x, key_padding_mask=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, T) - Input token indices\n",
    "        key_padding_mask: (B, T) - Boolean mask (True for padding positions)\n",
    "    Returns:\n",
    "        (B, T, d_embd) - Encoded representations\n",
    "    \"\"\"\n",
    "    tok_emb = self.tok_emb(x)\n",
    "    pos_emb = self.pos_emb(x)\n",
    "    x = tok_emb + pos_emb\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x, key_padding_mask=key_padding_mask)\n",
    "\n",
    "    x = self.ln_f(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeb9tmpNaEVt"
   },
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "2dCebYf7aEVt"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "  \"\"\"\n",
    "  Decoder block with:\n",
    "  1. Masked multi-head self-attention (causal)\n",
    "  2. Multi-head cross-attention to encoder output\n",
    "  3. Feed-forward network\n",
    "\n",
    "  Args:\n",
    "    d_embd: dimension of the embeddings\n",
    "    n_heads: number of attention heads\n",
    "    dropout: dropout rate\n",
    "  \"\"\"\n",
    "  def __init__(self, d_embd, n_heads, dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.ln1 = nn.LayerNorm(d_embd)\n",
    "    self.ln2 = nn.LayerNorm(d_embd)\n",
    "    self.ln3 = nn.LayerNorm(d_embd)\n",
    "\n",
    "    self.self_attn = MultiHeadAttention(d_embd, n_heads, dropout)\n",
    "    self.cross_attn = MultiHeadAttention(d_embd, n_heads, dropout)\n",
    "\n",
    "    self.mlp = MLP(d_embd, dropout)\n",
    "\n",
    "  def forward(self, x, encoder_out, tgt_key_padding_mask=None, src_key_padding_mask=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, T_tgt, d_embd) - Decoder input\n",
    "        encoder_out: (B, T_src, d_embd) - Encoder output\n",
    "        tgt_key_padding_mask: (B, T_tgt) - Decoder padding mask\n",
    "        src_key_padding_mask: (B, T_src) - Encoder padding mask\n",
    "    \"\"\"\n",
    "    # 1. Masked self-attention (decoder attends to previous positions)\n",
    "    x = x + self.self_attn(\n",
    "        self.ln1(x),\n",
    "        src=None,\n",
    "        key_padding_mask=tgt_key_padding_mask,\n",
    "        causal_mask=True\n",
    "    )\n",
    "\n",
    "    # 2. Cross-attention (decoder attends to encoder output)\n",
    "    x = x + self.cross_attn(\n",
    "        self.ln2(x),\n",
    "        src=encoder_out,\n",
    "        key_padding_mask=src_key_padding_mask,\n",
    "        causal_mask=False\n",
    "    )\n",
    "\n",
    "    x = x + self.mlp(self.ln3(x))\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "TFZbwIWnaEVt"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  \"\"\"\n",
    "  Decoder with multiple blocks of masked multi-head self-attention and cross-attention\n",
    "\n",
    "  Args:\n",
    "    vocab_size: size of the vocabulary\n",
    "    d_embd: dimension of the embeddings\n",
    "    n_heads: number of attention heads\n",
    "    dropout: dropout rate\n",
    "    n_blocks: number of decoder blocks\n",
    "  \"\"\"\n",
    "  def __init__(self, vocab_size, d_embd, n_heads, dropout=0.1, n_blocks=4):\n",
    "    super().__init__()\n",
    "    self.tok_emb = TokenEmbedding(vocab_size, d_embd, padding_idx=stoi['<PAD>'])\n",
    "    self.pos_emb = PositionalEmbedding(context_window, d_embd)\n",
    "    self.blocks = nn.ModuleList([DecoderBlock(d_embd, n_heads, dropout) for _ in range(n_blocks)])\n",
    "    self.ln_f = nn.LayerNorm(d_embd)\n",
    "    self.lm_head = nn.Linear(d_embd, vocab_size)\n",
    "\n",
    "  def forward(self, x, encoder_out, tgt_key_padding_mask=None, src_key_padding_mask=None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (B, T_tgt, vocab_size) - Logits for each position\n",
    "    \"\"\"\n",
    "    tok_emb = self.tok_emb(x)\n",
    "    pos_emb = self.pos_emb(x)\n",
    "    x = tok_emb + pos_emb\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x, encoder_out, tgt_key_padding_mask, src_key_padding_mask)\n",
    "\n",
    "    x = self.ln_f(x)\n",
    "    logits = self.lm_head(x)\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNOdCRmIaEVt"
   },
   "source": [
    "Testing transformer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "wknruBviaEVt",
    "outputId": "4e2eb5c2-4380-4f3f-95ff-73865cdd5b7b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# Test the Encoder-Decoder architecture\\nprint(\"=\"*60)\\nprint(\"Testing Encoder-Decoder Architecture\")\\nprint(\"=\"*60)\\n\\n# Get a batch from the data loader\\nx_batch, y_batch = next(iter(train_loader))\\n\\n# Create masks\\nsrc_key_padding_mask = (x_batch == stoi[\\'<PAD>\\'])  # Encoder mask\\ntgt_key_padding_mask = (y_batch == stoi[\\'<PAD>\\'])  # Decoder mask\\n\\nprint(f\"\\nInput shapes:\")\\nprint(f\"  English (source): {x_batch.shape}\")\\nprint(f\"  Italian (target): {y_batch.shape}\")\\n\\n# Initialize encoder and decoder with multi-head attention\\nencoder = Encoder(vocab_size, d_embd, n_heads, dropout=0.1, n_blocks=2)\\ndecoder = Decoder(vocab_size, d_embd, n_heads, dropout=0.1, n_blocks=2)\\n\\nprint(f\"\\nEncoder parameters: {sum(p.numel() for p in encoder.parameters()):,}\")\\nprint(f\"Decoder parameters: {sum(p.numel() for p in decoder.parameters()):,}\")\\n\\n# Forward pass through encoder\\nencoder_out = encoder(x_batch, key_padding_mask=src_key_padding_mask)\\nprint(f\"\\nEncoder output shape: {encoder_out.shape}\")\\n\\n# Forward pass through decoder\\nlogits = decoder(\\n    y_batch, \\n    encoder_out, \\n    tgt_key_padding_mask=tgt_key_padding_mask,\\n    src_key_padding_mask=src_key_padding_mask\\n)\\nprint(f\"Decoder output (logits) shape: {logits.shape}\")\\nprint(f\"Expected shape: (batch_size={x_batch.shape[0]}, seq_len={y_batch.shape[1]}, vocab_size={vocab_size})\")\\n\\nprint(\"\\n✓ Encoder-Decoder architecture working correctly!\")\\n'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Test the Encoder-Decoder architecture\n",
    "print(\"=\"*60)\n",
    "print(\"Testing Encoder-Decoder Architecture\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get a batch from the data loader\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "# Create masks\n",
    "src_key_padding_mask = (x_batch == stoi['<PAD>'])  # Encoder mask\n",
    "tgt_key_padding_mask = (y_batch == stoi['<PAD>'])  # Decoder mask\n",
    "\n",
    "print(f\"\\nInput shapes:\")\n",
    "print(f\"  English (source): {x_batch.shape}\")\n",
    "print(f\"  Italian (target): {y_batch.shape}\")\n",
    "\n",
    "# Initialize encoder and decoder with multi-head attention\n",
    "encoder = Encoder(vocab_size, d_embd, n_heads, dropout=0.1, n_blocks=2)\n",
    "decoder = Decoder(vocab_size, d_embd, n_heads, dropout=0.1, n_blocks=2)\n",
    "\n",
    "print(f\"\\nEncoder parameters: {sum(p.numel() for p in encoder.parameters()):,}\")\n",
    "print(f\"Decoder parameters: {sum(p.numel() for p in decoder.parameters()):,}\")\n",
    "\n",
    "# Forward pass through encoder\n",
    "encoder_out = encoder(x_batch, key_padding_mask=src_key_padding_mask)\n",
    "print(f\"\\nEncoder output shape: {encoder_out.shape}\")\n",
    "\n",
    "# Forward pass through decoder\n",
    "logits = decoder(\n",
    "    y_batch,\n",
    "    encoder_out,\n",
    "    tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "    src_key_padding_mask=src_key_padding_mask\n",
    ")\n",
    "print(f\"Decoder output (logits) shape: {logits.shape}\")\n",
    "print(f\"Expected shape: (batch_size={x_batch.shape[0]}, seq_len={y_batch.shape[1]}, vocab_size={vocab_size})\")\n",
    "\n",
    "print(\"\\n✓ Encoder-Decoder architecture working correctly!\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04rvAYJ-aEVu"
   },
   "source": [
    "Seq2Seq Encoder/Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "abs3qbEhaEVu"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "  \"\"\"\n",
    "  Complete Seq2Seq Translation Model combining Encoder and Decoder\n",
    "  \"\"\"\n",
    "  def __init__(self, vocab_size, d_embd, n_heads, dropout=0.1, n_encoder_blocks=4, n_decoder_blocks=4):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(vocab_size, d_embd, n_heads, dropout, n_encoder_blocks)\n",
    "    self.decoder = Decoder(vocab_size, d_embd, n_heads, dropout, n_decoder_blocks)\n",
    "\n",
    "  def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        src: (B, T_src) - Source token indices (English)\n",
    "        tgt: (B, T_tgt) - Target token indices (Italian)\n",
    "        src_key_padding_mask: (B, T_src) - Source padding mask\n",
    "        tgt_key_padding_mask: (B, T_tgt) - Target padding mask\n",
    "    Returns:\n",
    "        logits: (B, T_tgt, vocab_size) - Logits for each target position\n",
    "    \"\"\"\n",
    "    # Encode source\n",
    "    encoder_out = self.encoder(src, key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    # Decode (with teacher forcing during training)\n",
    "    logits = self.decoder(\n",
    "        tgt,\n",
    "        encoder_out,\n",
    "        tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "        src_key_padding_mask=src_key_padding_mask\n",
    "    )\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsCciGqHaEVu"
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "yxi3l5lWaEVu"
   },
   "outputs": [],
   "source": [
    "d_embd = 64\n",
    "n_heads = 8\n",
    "head_size = d_embd // n_heads\n",
    "n_encoder_blocks = 4\n",
    "n_decoder_blocks = 4\n",
    "dropout = 0.4\n",
    "lr = 3e-4\n",
    "adam_weight_decay = 0.01\n",
    "\n",
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajRNr3B9aEVu"
   },
   "source": [
    "Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gR2XveI2aEVu",
    "outputId": "d9d83f5e-19aa-4f5b-ffe3-83edfc037bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total parameters: 731,467\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize model\n",
    "model = Seq2SeqModel(\n",
    "    vocab_size=vocab_size,\n",
    "    d_embd=d_embd,\n",
    "    n_heads=n_heads,\n",
    "    dropout=dropout,\n",
    "    n_encoder_blocks=n_encoder_blocks,\n",
    "    n_decoder_blocks=n_decoder_blocks\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1A1X-J5ZaEVu",
    "outputId": "35eb4318-1efa-4d38-9bc4-be7b4e359f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function - ignore padding tokens\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi['<PAD>'], reduction='mean')\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=adam_weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvUNsgFJaEVu"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "qyGacO1iaEVu"
   },
   "outputs": [],
   "source": [
    "print_every = 50  # Print loss every N batches\n",
    "eval_every = 500  # Evaluate on validation set every N batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "UXsQT65HaEVz"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on a data loader and return average loss.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in data_loader:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_target = tgt[:, 1:]\n",
    "\n",
    "            src_mask = (src == stoi['<PAD>'])\n",
    "            tgt_mask = (tgt_input == stoi['<PAD>'])\n",
    "\n",
    "            logits = model(\n",
    "                src=src,\n",
    "                tgt=tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_mask\n",
    "            )\n",
    "\n",
    "            loss = criterion(logits.reshape(-1, vocab_size), tgt_target.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / total_batches if total_batches > 0 else 0.0\n",
    "    model.train()\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjvDkvktaEVz",
    "outputId": "e9b25cdb-a96c-403b-efe8-84298c637359"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Training\n",
      "============================================================\n",
      "Epoch 1/150, Batch 0/32, Loss: 7.2238, LR: 0.000300\n",
      "\n",
      "Epoch 1/150 Summary:\n",
      "  Train Loss: 6.2723\n",
      "  Val Loss:   5.4122\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 2/150, Batch 0/32, Loss: 5.5411, LR: 0.000300\n",
      "\n",
      "Epoch 2/150 Summary:\n",
      "  Train Loss: 5.0079\n",
      "  Val Loss:   4.3637\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 3/150, Batch 0/32, Loss: 4.4282, LR: 0.000300\n",
      "\n",
      "Epoch 3/150 Summary:\n",
      "  Train Loss: 4.0662\n",
      "  Val Loss:   3.6022\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 4/150, Batch 0/32, Loss: 3.6735, LR: 0.000300\n",
      "\n",
      "Epoch 4/150 Summary:\n",
      "  Train Loss: 3.4613\n",
      "  Val Loss:   3.2173\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 5/150, Batch 0/32, Loss: 3.2462, LR: 0.000300\n",
      "\n",
      "Epoch 5/150 Summary:\n",
      "  Train Loss: 3.1708\n",
      "  Val Loss:   3.0288\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 6/150, Batch 0/32, Loss: 3.1934, LR: 0.000300\n",
      "\n",
      "Epoch 6/150 Summary:\n",
      "  Train Loss: 3.0180\n",
      "  Val Loss:   2.9285\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 7/150, Batch 0/32, Loss: 2.9396, LR: 0.000300\n",
      "\n",
      "Epoch 7/150 Summary:\n",
      "  Train Loss: 2.9308\n",
      "  Val Loss:   2.8614\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 8/150, Batch 0/32, Loss: 2.8167, LR: 0.000300\n",
      "\n",
      "Epoch 8/150 Summary:\n",
      "  Train Loss: 2.8620\n",
      "  Val Loss:   2.8106\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 9/150, Batch 0/32, Loss: 2.7905, LR: 0.000300\n",
      "\n",
      "Epoch 9/150 Summary:\n",
      "  Train Loss: 2.7913\n",
      "  Val Loss:   2.7692\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 10/150, Batch 0/32, Loss: 2.7103, LR: 0.000300\n",
      "\n",
      "Epoch 10/150 Summary:\n",
      "  Train Loss: 2.7468\n",
      "  Val Loss:   2.7356\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 11/150, Batch 0/32, Loss: 2.6150, LR: 0.000300\n",
      "\n",
      "Epoch 11/150 Summary:\n",
      "  Train Loss: 2.7003\n",
      "  Val Loss:   2.7103\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 12/150, Batch 0/32, Loss: 2.6440, LR: 0.000300\n",
      "\n",
      "Epoch 12/150 Summary:\n",
      "  Train Loss: 2.6641\n",
      "  Val Loss:   2.6823\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 13/150, Batch 0/32, Loss: 2.6977, LR: 0.000300\n",
      "\n",
      "Epoch 13/150 Summary:\n",
      "  Train Loss: 2.6304\n",
      "  Val Loss:   2.6633\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 14/150, Batch 0/32, Loss: 2.7622, LR: 0.000300\n",
      "\n",
      "Epoch 14/150 Summary:\n",
      "  Train Loss: 2.6058\n",
      "  Val Loss:   2.6453\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 15/150, Batch 0/32, Loss: 2.5536, LR: 0.000300\n",
      "\n",
      "Epoch 15/150 Summary:\n",
      "  Train Loss: 2.5786\n",
      "  Val Loss:   2.6268\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 16/150, Batch 0/32, Loss: 2.4980, LR: 0.000300\n",
      "\n",
      "Epoch 16/150 Summary:\n",
      "  Train Loss: 2.5492\n",
      "  Val Loss:   2.6178\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 17/150, Batch 0/32, Loss: 2.4667, LR: 0.000300\n",
      "\n",
      "Epoch 17/150 Summary:\n",
      "  Train Loss: 2.5331\n",
      "  Val Loss:   2.6041\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 18/150, Batch 0/32, Loss: 2.5199, LR: 0.000300\n",
      "\n",
      "Epoch 18/150 Summary:\n",
      "  Train Loss: 2.5057\n",
      "  Val Loss:   2.5944\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 19/150, Batch 0/32, Loss: 2.4330, LR: 0.000300\n",
      "\n",
      "Epoch 19/150 Summary:\n",
      "  Train Loss: 2.4833\n",
      "  Val Loss:   2.5823\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 20/150, Batch 0/32, Loss: 2.4087, LR: 0.000300\n",
      "\n",
      "Epoch 20/150 Summary:\n",
      "  Train Loss: 2.4704\n",
      "  Val Loss:   2.5739\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 21/150, Batch 0/32, Loss: 2.3071, LR: 0.000300\n",
      "\n",
      "Epoch 21/150 Summary:\n",
      "  Train Loss: 2.4486\n",
      "  Val Loss:   2.5642\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 22/150, Batch 0/32, Loss: 2.4392, LR: 0.000300\n",
      "\n",
      "Epoch 22/150 Summary:\n",
      "  Train Loss: 2.4294\n",
      "  Val Loss:   2.5581\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 23/150, Batch 0/32, Loss: 2.6511, LR: 0.000300\n",
      "\n",
      "Epoch 23/150 Summary:\n",
      "  Train Loss: 2.4245\n",
      "  Val Loss:   2.5527\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 24/150, Batch 0/32, Loss: 2.3236, LR: 0.000300\n",
      "\n",
      "Epoch 24/150 Summary:\n",
      "  Train Loss: 2.4050\n",
      "  Val Loss:   2.5447\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 25/150, Batch 0/32, Loss: 2.3290, LR: 0.000300\n",
      "\n",
      "Epoch 25/150 Summary:\n",
      "  Train Loss: 2.3893\n",
      "  Val Loss:   2.5400\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 26/150, Batch 0/32, Loss: 2.3025, LR: 0.000300\n",
      "\n",
      "Epoch 26/150 Summary:\n",
      "  Train Loss: 2.3694\n",
      "  Val Loss:   2.5333\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 27/150, Batch 0/32, Loss: 2.3418, LR: 0.000300\n",
      "\n",
      "Epoch 27/150 Summary:\n",
      "  Train Loss: 2.3533\n",
      "  Val Loss:   2.5362\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 28/150, Batch 0/32, Loss: 2.2867, LR: 0.000300\n",
      "\n",
      "Epoch 28/150 Summary:\n",
      "  Train Loss: 2.3403\n",
      "  Val Loss:   2.5326\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 29/150, Batch 0/32, Loss: 2.3410, LR: 0.000300\n",
      "\n",
      "Epoch 29/150 Summary:\n",
      "  Train Loss: 2.3311\n",
      "  Val Loss:   2.5235\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 30/150, Batch 0/32, Loss: 2.3379, LR: 0.000300\n",
      "\n",
      "Epoch 30/150 Summary:\n",
      "  Train Loss: 2.3149\n",
      "  Val Loss:   2.5247\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 31/150, Batch 0/32, Loss: 2.2943, LR: 0.000300\n",
      "\n",
      "Epoch 31/150 Summary:\n",
      "  Train Loss: 2.3131\n",
      "  Val Loss:   2.5186\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 32/150, Batch 0/32, Loss: 2.2677, LR: 0.000300\n",
      "\n",
      "Epoch 32/150 Summary:\n",
      "  Train Loss: 2.2999\n",
      "  Val Loss:   2.5164\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 33/150, Batch 0/32, Loss: 2.2477, LR: 0.000300\n",
      "\n",
      "Epoch 33/150 Summary:\n",
      "  Train Loss: 2.2851\n",
      "  Val Loss:   2.5152\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 34/150, Batch 0/32, Loss: 2.3980, LR: 0.000300\n",
      "\n",
      "Epoch 34/150 Summary:\n",
      "  Train Loss: 2.2650\n",
      "  Val Loss:   2.5164\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 35/150, Batch 0/32, Loss: 2.2695, LR: 0.000300\n",
      "\n",
      "Epoch 35/150 Summary:\n",
      "  Train Loss: 2.2629\n",
      "  Val Loss:   2.5115\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 36/150, Batch 0/32, Loss: 2.3589, LR: 0.000300\n",
      "\n",
      "Epoch 36/150 Summary:\n",
      "  Train Loss: 2.2523\n",
      "  Val Loss:   2.5067\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 37/150, Batch 0/32, Loss: 2.2065, LR: 0.000300\n",
      "\n",
      "Epoch 37/150 Summary:\n",
      "  Train Loss: 2.2316\n",
      "  Val Loss:   2.5080\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 38/150, Batch 0/32, Loss: 2.2574, LR: 0.000300\n",
      "\n",
      "Epoch 38/150 Summary:\n",
      "  Train Loss: 2.2245\n",
      "  Val Loss:   2.5097\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 39/150, Batch 0/32, Loss: 2.2262, LR: 0.000300\n",
      "\n",
      "Epoch 39/150 Summary:\n",
      "  Train Loss: 2.2208\n",
      "  Val Loss:   2.5071\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 40/150, Batch 0/32, Loss: 2.3072, LR: 0.000300\n",
      "\n",
      "Epoch 40/150 Summary:\n",
      "  Train Loss: 2.2049\n",
      "  Val Loss:   2.5069\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 41/150, Batch 0/32, Loss: 2.1908, LR: 0.000300\n",
      "\n",
      "Epoch 41/150 Summary:\n",
      "  Train Loss: 2.2058\n",
      "  Val Loss:   2.5049\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 42/150, Batch 0/32, Loss: 2.2744, LR: 0.000300\n",
      "\n",
      "Epoch 42/150 Summary:\n",
      "  Train Loss: 2.1853\n",
      "  Val Loss:   2.5045\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 43/150, Batch 0/32, Loss: 2.2418, LR: 0.000300\n",
      "\n",
      "Epoch 43/150 Summary:\n",
      "  Train Loss: 2.1864\n",
      "  Val Loss:   2.5106\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 44/150, Batch 0/32, Loss: 2.0810, LR: 0.000300\n",
      "\n",
      "Epoch 44/150 Summary:\n",
      "  Train Loss: 2.1771\n",
      "  Val Loss:   2.5067\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 45/150, Batch 0/32, Loss: 2.1524, LR: 0.000300\n",
      "\n",
      "Epoch 45/150 Summary:\n",
      "  Train Loss: 2.1735\n",
      "  Val Loss:   2.5038\n",
      "  LR:         0.000300\n",
      "------------------------------------------------------------\n",
      "Epoch 46/150, Batch 0/32, Loss: 2.1088, LR: 0.000300\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch_idx, (src, tgt) in enumerate(train_loader):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_target = tgt[:, 1:]\n",
    "\n",
    "        src_mask = (src == stoi['<PAD>'])\n",
    "        tgt_mask = (tgt_input == stoi['<PAD>'])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(\n",
    "            src=src,\n",
    "            tgt=tgt_input,\n",
    "            src_key_padding_mask=src_mask,\n",
    "            tgt_key_padding_mask=tgt_mask\n",
    "        )\n",
    "\n",
    "        loss = criterion(logits.reshape(-1, vocab_size), tgt_target.reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        if batch_idx % print_every == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, \"\n",
    "                  f\"Loss: {loss.item():.4f}, LR: {current_lr:.6f}\")\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / num_batches if num_batches > 0 else 0.0\n",
    "    train_losses.append(avg_epoch_loss)\n",
    "\n",
    "    avg_val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(f\"  Train Loss: {avg_epoch_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"  LR:         {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sot4ZoVhaEV0"
   },
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lh4jKmhlaEV0"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(train_losses) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "    plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "\n",
    "    if len(val_losses) > 0:\n",
    "        plt.plot(epochs[:len(val_losses)], val_losses, label='Val Loss', marker='s')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nFinal Training Loss: {train_losses[-1]:.4f}\")\n",
    "    if len(val_losses) > 0:\n",
    "        print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1dPK2ZyQNUu"
   },
   "source": [
    "# Results\n",
    "\n",
    "## 50 samples\n",
    "\n",
    "### 100 epochs\n",
    "\n",
    "- d_embd = 128 -> overfitting in general\n",
    "- d_embd = 64 - n_head = 8 -> 3.185 val loss\n",
    "- d_embd = 64 - n_head = 4 -> 3.19 val loss\n",
    "- d_embd = 64 - n_head = 2 -> 3.19 val loss\n",
    "- d_embd = 32 - n_head = 8 -> 3.59 train loss / 3.62 val loss (good but not good)\n",
    "\n",
    "### 200 epochs\n",
    "- d_embd = 64 - n_head = 8 -> it goes up, bad\n",
    "\n",
    "## More sample data to train on (100 samples)\n",
    "\n",
    "- d_embd = 128 - n_head = 8 - dropout = 0.2 -> 0.15 train loss / 4.75 val loss (yoooooo wtf)\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.2 -> 3.088 val loss\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.1 -> 3.3 val loss\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.2 - lr = 1e-3 -> shitty shit\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.2 - lr = 2e-4 -> 2.88 val loss\n",
    "\n",
    "### 150 epochs\n",
    "\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.2 - lr = 2e-4 -> overfitting\n",
    "\n",
    "## Even more sample data to train on (500 samples)\n",
    "\n",
    "### 150 epochs\n",
    "\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.2 - lr = 2e-4 -> overfitting\n",
    "\n",
    "## MORE DATA (1000 samples)\n",
    "\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.2 - lr = 2e-4 -> still overfitting\n",
    "- d_embd = 64 - n_head = 4 - dropout = 0.3 - lr = 2e-4 -> 2.9 val loss\n",
    "- d_embd = 64 - n_head = 8 - dropout = 0.3 - lr = 2e-4 -> 2.97 val loss\n",
    "- d_embd = 64 - n_head = 8 - dropout = 0.4 - lr = 3e-4 ->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTHOxNJFaEV0"
   },
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skWcrFqjaEV0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Save model checkpoint\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'epoch': num_epochs,\n",
    "    'vocab_size': vocab_size,\n",
    "    'd_embd': d_embd,\n",
    "    'n_heads': n_heads,\n",
    "    'stoi': stoi,\n",
    "    'itos': itos\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'bertolingo_model.pt')\n",
    "print(\"Model saved to 'bertolingo_model.pt'\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAACHw9NaEV0"
   },
   "source": [
    "Inference (translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mwOI5kWaEV0"
   },
   "outputs": [],
   "source": [
    "def translate(model, src_text, stoi, itos, device, max_len=128):\n",
    "    \"\"\"\n",
    "    Translate English text to Italian using the trained model\n",
    "\n",
    "    Args:\n",
    "        model: Trained Seq2Seq model\n",
    "        src_text: English text string\n",
    "        stoi: String to index mapping\n",
    "        itos: Index to string mapping\n",
    "        device: Device to run on\n",
    "        max_len: Maximum translation length\n",
    "    Returns:\n",
    "        Translated Italian text\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Encode source text\n",
    "    src_tokens = torch.tensor([[stoi.get(char, stoi['<PAD>']) for char in src_text]], device=device)\n",
    "    src_mask = (src_tokens == stoi['<PAD>'])\n",
    "\n",
    "    # Encode source\n",
    "    with torch.no_grad():\n",
    "        encoder_out = model.encoder(src_tokens, key_padding_mask=src_mask)\n",
    "\n",
    "        # Start with first token (or padding if we had BOS)\n",
    "        tgt_tokens = torch.tensor([[stoi.get(src_text[0], stoi['<PAD>'])]], device=device)\n",
    "\n",
    "        # Autoregressive decoding\n",
    "        for _ in range(max_len):\n",
    "            tgt_mask = (tgt_tokens == stoi['<PAD>'])\n",
    "            logits = model.decoder(\n",
    "                tgt_tokens,\n",
    "                encoder_out,\n",
    "                tgt_key_padding_mask=tgt_mask,\n",
    "                src_key_padding_mask=src_mask\n",
    "            )\n",
    "\n",
    "            # Get next token (greedy decoding)\n",
    "            next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "            tgt_tokens = torch.cat([tgt_tokens, next_token], dim=1)\n",
    "\n",
    "            # Stop if padding token (or could add EOS token)\n",
    "            if next_token.item() == stoi['<PAD>']:\n",
    "                break\n",
    "\n",
    "    # Decode target tokens\n",
    "    translated = ''.join([itos.get(idx.item(), '') for idx in tgt_tokens[0]])\n",
    "\n",
    "    return translated\n",
    "\n",
    "# Test translation on a sample\n",
    "print(\"Testing translation...\")\n",
    "test_english = \"Hello, how are you?\"\n",
    "print(f\"English: {test_english}\")\n",
    "print(f\"Italian: {translate(model, test_english, stoi, itos, device)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RB7zI6KNj-a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}